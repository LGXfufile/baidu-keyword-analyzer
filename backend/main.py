from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from database import get_db, create_tables
from models import (
    KeywordAnalysisRequest, 
    KeywordAnalysisResponse,
    SearchHistoryResponse,
    VariantTypesResponse,
    ProgressUpdate,
    ExportRequest
)
from services.keyword_service import KeywordService
from services.business_analyzer import BusinessAnalyzer
from config import settings
import asyncio
import logging
import json
import pandas as pd
import io
from typing import List

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title=settings.APP_NAME,
    version=settings.VERSION,
    description="ç™¾åº¦å…³é”®è¯ä¸‹æ‹‰è¯åˆ†æå·¥å…·API"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å­˜å‚¨åˆ†æè¿›åº¦
analysis_progress = {}

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆ›å»ºæ•°æ®åº“è¡¨"""
    await create_tables()
    logger.info("åº”ç”¨å¯åŠ¨æˆåŠŸ")

@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "message": "ç™¾åº¦å…³é”®è¯åˆ†æå™¨API",
        "version": settings.VERSION,
        "status": "running"
    }

@app.get("/api/variant-types", response_model=VariantTypesResponse)
async def get_variant_types():
    """è·å–å¯ç”¨çš„å…³é”®è¯å˜ä½“ç±»å‹"""
    return VariantTypesResponse(variant_types=KeywordService.VARIANT_TYPES)

@app.post("/api/analyze", response_model=KeywordAnalysisResponse)
async def analyze_keyword(
    request: KeywordAnalysisRequest,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db)
):
    """åˆ†æå…³é”®è¯å¹¶è·å–ä¸‹æ‹‰è¯"""
    try:
        # éªŒè¯å˜ä½“ç±»å‹
        invalid_types = [vt for vt in request.variant_types if vt not in KeywordService.VARIANT_TYPES]
        if invalid_types:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„å˜ä½“ç±»å‹: {invalid_types}")
        
        # ç”Ÿæˆå”¯ä¸€ä¼šè¯ID
        import uuid
        session_id = str(uuid.uuid4())
        
        # åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª
        analysis_progress[session_id] = {
            'processed': 0,
            'total': 0,
            'percentage': 0.0,
            'status': 'running',
            'error': None
        }
        
        # è¿›åº¦å›è°ƒå‡½æ•°
        async def progress_callback(processed: int, total: int):
            analysis_progress[session_id].update({
                'processed': processed,
                'total': total,
                'percentage': round((processed / total) * 100, 2) if total > 0 else 0,
                'status': 'running'
            })
        
        # æ‰§è¡Œåˆ†æ
        try:
            result = await KeywordService.analyze_keywords(
                request.keyword,
                request.variant_types,
                db,
                progress_callback,
                session_id  # ä¼ é€’session_idç¡®ä¿ä¸€è‡´æ€§
            )
            
            # session_idå·²ç»åœ¨resultä¸­äº†
            
            # æ ‡è®°å®Œæˆ
            analysis_progress[session_id].update({
                'status': 'completed',
                'percentage': 100.0
            })
            
            return KeywordAnalysisResponse(**result)
            
        except Exception as e:
            # æ ‡è®°é”™è¯¯
            analysis_progress[session_id].update({
                'status': 'error',
                'error': str(e)
            })
            logger.error(f"å…³é”®è¯åˆ†æå¤±è´¥: {str(e)}")
            raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")
        
    except Exception as e:
        logger.error(f"å…³é”®è¯åˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")

@app.get("/api/progress/{session_id}")
async def get_analysis_progress(session_id: str):
    """è·å–åˆ†æè¿›åº¦"""
    if session_id in analysis_progress:
        progress = analysis_progress[session_id]
        return {
            'session_id': session_id,
            'processed': progress.get('processed', 0),
            'total': progress.get('total', 0), 
            'percentage': progress.get('percentage', 0.0),
            'status': progress.get('status', 'unknown'),
            'error': progress.get('error')
        }
    else:
        return {
            'session_id': session_id,
            'processed': 0,
            'total': 0,
            'percentage': 0.0,
            'status': 'not_found',
            'error': 'ä¼šè¯ä¸å­˜åœ¨'
        }

@app.get("/api/history", response_model=List[SearchHistoryResponse])
async def get_search_history(
    limit: int = 10,
    db: AsyncSession = Depends(get_db)
):
    """è·å–æœç´¢å†å²"""
    try:
        histories = await KeywordService.get_search_history(db, limit)
        return [SearchHistoryResponse(**h) for h in histories]
    except Exception as e:
        logger.error(f"è·å–æœç´¢å†å²å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å†å²å¤±è´¥: {str(e)}")

@app.get("/api/results/{session_id}")
async def get_session_results(
    session_id: str,
    db: AsyncSession = Depends(get_db)
):
    """è·å–ç‰¹å®šä¼šè¯çš„åˆ†æç»“æœ"""
    try:
        results = await KeywordService.get_session_results(session_id, db)
        return results
    except Exception as e:
        logger.error(f"è·å–ä¼šè¯ç»“æœå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç»“æœå¤±è´¥: {str(e)}")

@app.get("/api/business-analysis/{session_id}")
async def get_business_analysis(
    session_id: str,
    db: AsyncSession = Depends(get_db)
):
    """è·å–å•†ä¸šä»·å€¼åˆ†æç»“æœ"""
    try:
        results = await KeywordService.get_session_results(session_id, db)
        
        # å¦‚æœç»“æœä¸­æ²¡æœ‰å•†ä¸šåˆ†æï¼Œåˆ™é‡æ–°ç”Ÿæˆ
        if 'business_analysis' not in results:
            # é‡æ–°åˆ†æå¹¶æ·»åŠ å•†ä¸šä»·å€¼
            results = KeywordService._add_business_analysis(results)
        
        return {
            'session_id': session_id,
            'business_analysis': results.get('business_analysis', {}),
            'summary': results.get('summary', {})
        }
    except Exception as e:
        logger.error(f"è·å–å•†ä¸šåˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å•†ä¸šåˆ†æå¤±è´¥: {str(e)}")

@app.post("/api/analyze-keyword")
async def analyze_single_keyword(request: dict):
    """åˆ†æå•ä¸ªå…³é”®è¯çš„å•†ä¸šä»·å€¼"""
    try:
        keyword = request.get('keyword', '')
        if not keyword:
            raise HTTPException(status_code=400, detail="å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        
        metrics = BusinessAnalyzer.analyze_keyword(keyword)
        
        return {
            'keyword': keyword,
            'commercial_score': metrics.commercial_score,
            'intent_type': metrics.intent_type,
            'competition_level': metrics.competition_level,
            'search_volume_estimate': metrics.search_volume_estimate,
            'difficulty_score': metrics.difficulty_score,
            'opportunity_score': metrics.opportunity_score
        }
    except Exception as e:
        logger.error(f"å•å…³é”®è¯åˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")

@app.post("/api/blue-ocean-discovery")
async def discover_blue_ocean_keywords(request: dict):
    """å‘ç°è“æµ·å…³é”®è¯"""
    try:
        keyword = request.get('keyword', '')
        limit = request.get('limit', 10)
        
        if not keyword:
            raise HTTPException(status_code=400, detail="å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        
        blue_oceans = await BusinessAnalyzer.discover_blue_ocean_keywords(keyword, limit)
        
        return {
            'keyword': keyword,
            'blue_ocean_count': len(blue_oceans),
            'blue_ocean_keywords': [
                {
                    'keyword': bo.keyword,
                    'opportunity_score': bo.opportunity_score,
                    'search_volume': bo.search_volume,
                    'competition_companies': bo.competition_companies,
                    'competition_level': bo.competition_level,
                    'sem_price': bo.sem_price,
                    'longtail_count': bo.longtail_count,
                    'platforms': bo.platforms,
                    'reasons': bo.reasons
                }
                for bo in blue_oceans
            ]
        }
    except Exception as e:
        logger.error(f"è“æµ·è¯å‘ç°å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å‘ç°å¤±è´¥: {str(e)}")

@app.post("/api/analyze-with-real-data")
async def analyze_keyword_with_real_data(request: dict):
    """ä½¿ç”¨5118çœŸå®æ•°æ®åˆ†æå…³é”®è¯"""
    try:
        keyword = request.get('keyword', '')
        enable_5118 = request.get('enable_5118', True)
        
        if not keyword:
            raise HTTPException(status_code=400, detail="å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        
        metrics = await BusinessAnalyzer.analyze_with_real_data(keyword, enable_5118)
        
        return {
            'keyword': keyword,
            'commercial_score': metrics.commercial_score,
            'intent_type': metrics.intent_type,
            'competition_level': metrics.competition_level,
            'search_volume_estimate': metrics.search_volume_estimate,
            'difficulty_score': metrics.difficulty_score,
            'opportunity_score': metrics.opportunity_score,
            'is_blue_ocean': metrics.is_blue_ocean,
            'real_data_available': metrics.real_data_available
        }
    except Exception as e:
        logger.error(f"çœŸå®æ•°æ®åˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")

@app.get("/api/business-insights/{session_id}")
async def get_business_insights(
    session_id: str,
    db: AsyncSession = Depends(get_db)
):
    """è·å–æ™ºèƒ½å•†ä¸šæ´å¯Ÿå’Œåˆ†å±‚æœºä¼š"""
    try:
        results = await KeywordService.get_session_results(session_id, db)
        
        # è·å–æ‰€æœ‰å»ºè®®è¯
        all_suggestions = []
        for variant_type, variants in results['results'].items():
            for variant_keyword, suggestions in variants.items():
                all_suggestions.extend(suggestions)
        
        if not all_suggestions:
            return {
                'session_id': session_id,
                'business_insights': {
                    'total_opportunities': 0,
                    'blue_ocean_count': 0,
                    'high_value_count': 0,
                    'avg_commercial_score': 0,
                    'total_search_volume': 0,
                    'categories': {},
                    'recommended_focus': [],
                    'insights': ['âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å»ºè®®è¯æ•°æ®']
                },
                'opportunities_by_tier': {},
                'recommendations': [],
                'summary_stats': {
                    'total_opportunities': 0,
                    'blue_ocean_count': 0,
                    'high_value_count': 0,
                    'avg_commercial_score': 0,
                    'total_search_volume': 0,
                    'total_count': 0,
                    'unique_count': 0,
                    'duplicate_removed': 0
                },
                'insights_messages': ['âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å»ºè®®è¯æ•°æ®ï¼Œè¯·é‡æ–°è¿›è¡Œå…³é”®è¯åˆ†æ']
            }
        
        # åˆ†æå»ºè®®è¯åˆ—è¡¨ - å¼ºåˆ¶ä½¿ç”¨5118çœŸå®æ•°æ®
        try:
            analysis = await BusinessAnalyzer.analyze_suggestion_list_with_real_data(all_suggestions, enable_5118=True)
        except Exception as e:
            logger.error(f"5118æ•°æ®åˆ†æå¤±è´¥: {str(e)}")
            # ä¼˜é›…é™çº§ï¼Œä½†æ˜ç¡®æ ‡æ˜æ˜¯ä¼°ç®—æ•°æ®
            analysis = BusinessAnalyzer.analyze_suggestion_list(all_suggestions)
            analysis['data_source_warning'] = 'âš ï¸ 5118çœŸå®æ•°æ®è·å–å¤±è´¥ï¼Œå·²é™çº§ä¸ºä¼°ç®—æ¨¡å¼'
        
        # ç”Ÿæˆå•†ä¸šæ´å¯Ÿ
        insights = BusinessAnalyzer.generate_business_insights(analysis['top_opportunities'])
        
        # æ·»åŠ å»é‡æ´å¯Ÿä¿¡æ¯
        duplicate_removed = analysis.get('duplicate_removed', 0)
        if duplicate_removed > 0:
            insights['insights'].insert(0, f"ğŸ§¹ æ™ºèƒ½å»é‡å¤„ç†ï¼šä» {analysis.get('total_count', 0)} ä¸ªåŸå§‹å»ºè®®ä¸­å»é™¤ {duplicate_removed} ä¸ªé‡å¤é¡¹ï¼Œä¿ç•™ {analysis.get('unique_count', 0)} ä¸ªæœ‰æ•ˆå…³é”®è¯")
        
        # æ·»åŠ æ•°æ®æºè­¦å‘Šï¼ˆå¦‚æœæœ‰ï¼‰
        if 'data_source_warning' in analysis:
            insights['insights'].insert(0, analysis['data_source_warning'])
        
        return {
            'session_id': session_id,
            'business_insights': insights,
            'opportunities_by_tier': insights['categories'],
            'recommendations': insights['recommended_focus'],
            'summary_stats': {
                'total_opportunities': insights['total_opportunities'],
                'blue_ocean_count': insights['blue_ocean_count'],
                'high_value_count': insights['high_value_count'],
                'avg_commercial_score': insights['avg_commercial_score'],
                'total_search_volume': insights['total_search_volume'],
                'total_count': analysis.get('total_count', 0),
                'unique_count': analysis.get('unique_count', 0),
                'duplicate_removed': analysis.get('duplicate_removed', 0)
            },
            'insights_messages': insights['insights']
        }
    except Exception as e:
        logger.error(f"å•†ä¸šæ´å¯Ÿåˆ†æå¤±è´¥: {str(e)}")
        error_message = f"å•†ä¸šæ´å¯Ÿåˆ†æå¤±è´¥: {str(e)}"
        
        # è¿”å›é”™è¯¯çŠ¶æ€è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        return {
            'session_id': session_id,
            'business_insights': {
                'total_opportunities': 0,
                'blue_ocean_count': 0,
                'high_value_count': 0,
                'avg_commercial_score': 0,
                'total_search_volume': 0,
                'categories': {},
                'recommended_focus': [],
                'insights': [f'âŒ {error_message}']
            },
            'opportunities_by_tier': {},
            'recommendations': [],
            'summary_stats': {
                'total_opportunities': 0,
                'blue_ocean_count': 0,
                'high_value_count': 0,
                'avg_commercial_score': 0,
                'total_search_volume': 0,
                'total_count': 0,
                'unique_count': 0,
                'duplicate_removed': 0
            },
            'insights_messages': [
                f'âŒ {error_message}',
                'ğŸ”§ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®åé‡è¯•',
                'ğŸ’¡ å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒ'
            ]
        }

@app.post("/api/export")
async def export_results(
    request: ExportRequest,
    db: AsyncSession = Depends(get_db)
):
    """å¯¼å‡ºåˆ†æç»“æœ"""
    try:
        results = await KeywordService.get_session_results(request.session_id, db)
        
        # å‡†å¤‡å¯¼å‡ºæ•°æ®
        export_data = []
        for variant_type, variants in results['results'].items():
            for variant_keyword, suggestions in variants.items():
                for rank, suggestion in enumerate(suggestions, 1):
                    export_data.append({
                        'å˜ä½“ç±»å‹': KeywordService.VARIANT_TYPES.get(variant_type, variant_type),
                        'å˜ä½“å…³é”®è¯': variant_keyword,
                        'ä¸‹æ‹‰å»ºè®®è¯': suggestion,
                        'æ’åº': rank
                    })
        
        if not export_data:
            raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
        
        if request.format == 'excel':
            # å¯¼å‡ºExcel
            df = pd.DataFrame(export_data)
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name='å…³é”®è¯åˆ†æç»“æœ')
            output.seek(0)
            
            return StreamingResponse(
                io.BytesIO(output.read()),
                media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                headers={"Content-Disposition": f"attachment; filename=keywords_{request.session_id}.xlsx"}
            )
            
        elif request.format == 'csv':
            # å¯¼å‡ºCSV
            df = pd.DataFrame(export_data)
            output = io.StringIO()
            df.to_csv(output, index=False, encoding='utf-8-sig')
            output.seek(0)
            
            return StreamingResponse(
                io.BytesIO(output.getvalue().encode('utf-8-sig')),
                media_type='text/csv',
                headers={"Content-Disposition": f"attachment; filename=keywords_{request.session_id}.csv"}
            )
            
        elif request.format == 'json':
            # å¯¼å‡ºJSON
            json_data = json.dumps(export_data, ensure_ascii=False, indent=2)
            
            return StreamingResponse(
                io.BytesIO(json_data.encode('utf-8')),
                media_type='application/json',
                headers={"Content-Disposition": f"attachment; filename=keywords_{request.session_id}.json"}
            )
        
        else:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼")
            
    except Exception as e:
        logger.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)